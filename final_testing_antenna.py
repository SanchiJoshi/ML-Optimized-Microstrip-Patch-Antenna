# -*- coding: utf-8 -*-
"""final_testing_antenna.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QYE9BD5vgF6FfzuOPHOSPm2se4_1WEUM
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score

from google.colab import files
uploaded = files.upload()
file_name = list(uploaded.keys())[0]
data = pd.read_excel(file_name)
data.head()

X = data.drop(columns=['Frequency (GHz)'])
y = data['Frequency (GHz)']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=5)
print(f"Training set size: {X_train.shape[0]}")
print(f"Test set size: {X_test.shape[0]}")

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""# **TRAINING SVR WITHOUT GENETIC ALGORITHM**"""

svr_model = SVR(kernel='rbf')
svr_model.fit(X_train_scaled, y_train)

# Predicting on the test set
y_pred = svr_model.predict(X_test_scaled)
# Calculating evaluation metrics
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error (MSE): {mse}")
print(f"R² Score: {r2}")

import numpy as np
# Define the new input data
new_data = np.array([[25, 8.6, 3, 15, 4, 12.1, 2.5, 12]])
new_data_df = pd.DataFrame(new_data, columns=X_train.columns)
# Scale the input data using the same scaler used for training
new_data_scaled = scaler.transform(new_data_df)
# Predict the frequency
predicted_frequency = svr_model.predict(new_data_scaled)
print(f"Predicted Frequency (GHz): {predicted_frequency[0]}")

# Define the new input data
new_data = np.array([[26, 8.8, 5.2, 14.8, 4, 12.2, 3, 10]])
new_data_df = pd.DataFrame(new_data, columns=X_train.columns)
# Scale the input data using the same scaler used for training
new_data_scaled = scaler.transform(new_data_df)
# Predict the frequency
predicted_frequency = svr_model.predict(new_data_scaled)
print(f"Predicted Frequency (GHz): {predicted_frequency[0]}")

"""## **IMPLEMENTING GENETIC ALGORITHM**"""

!pip install deap

from sklearn.model_selection import cross_val_score
from deap import base, creator, tools, algorithms
import numpy as np
# Defining the fitness function for GA
def fitness_function(params):
    C, epsilon, gamma = params
    if C <= 0 or epsilon <= 0 or gamma <= 0:  # Ensure positive values
        return float('inf'),  # High fitness value for invalid parameters
    svr = SVR(kernel='rbf', C=C, epsilon=epsilon, gamma=gamma)
    scores = cross_val_score(svr, X_train_scaled, y_train, cv=3, scoring='neg_mean_squared_error')
    return -np.mean(scores),  # Minimize negative MSE

# Create the individual and population
creator.create("FitnessMin", base.Fitness, weights=(-1.0,))  # Minimize MSE
creator.create("Individual", list, fitness=creator.FitnessMin)

toolbox = base.Toolbox()

# Define attribute initialization ranges
toolbox.register("attr_C", np.random.uniform, 0.1, 100)  # C: [0.1, 100]
toolbox.register("attr_epsilon", np.random.uniform, 0.01, 1)  # epsilon: [0.01, 1]
toolbox.register("attr_gamma", np.random.uniform, 0.0001, 1)  # gamma: [0.0001, 1]

# Define individual and population
toolbox.register(
    "individual",
    tools.initCycle,
    creator.Individual,
    (toolbox.attr_C, toolbox.attr_epsilon, toolbox.attr_gamma),
    n=1,
)
toolbox.register("population", tools.initRepeat, list, toolbox.individual)

# Define GA operators
toolbox.register("mate", tools.cxBlend, alpha=0.5)
toolbox.register("mutate", tools.mutGaussian, mu=0, sigma=1, indpb=0.2)

# Custom mutation to enforce valid ranges
def custom_mutation(individual, indpb):
    individual[0] = max(0.1, min(100, individual[0]))  # C: [0.1, 100]
    individual[1] = max(0.01, min(1, individual[1]))  # epsilon: [0.01, 1]
    individual[2] = max(0.0001, min(1, individual[2]))  # gamma: [0.0001, 1]
    return individual,

toolbox.register("mutate", custom_mutation, indpb=0.2)
toolbox.register("select", tools.selTournament, tournsize=3)
toolbox.register("evaluate", fitness_function)

# Create an initial population
population = toolbox.population(n=30)  # Population size
ngen = 50                              # Number of generations
cxpb = 0.7                             # Crossover probability
mutpb = 0.2                            # Mutation probability

# Run the genetic algorithm
result, logbook = algorithms.eaSimple(population, toolbox, cxpb, mutpb, ngen, verbose=True)

# Extract the best individual
best_individual = tools.selBest(population, k=1)[0]
print("Best Parameters (C, epsilon, gamma):", best_individual)

# Train SVR with the best hyperparameters
optimized_svr = SVR(kernel='rbf', C=best_individual[0], epsilon=best_individual[1], gamma=best_individual[2])
optimized_svr.fit(X_train_scaled, y_train)

# Predict on test set
y_pred_optimized = optimized_svr.predict(X_test_scaled)

# Evaluate
mse_optimized = mean_squared_error(y_test, y_pred_optimized)
r2_optimized = r2_score(y_test, y_pred_optimized)

print(f"Optimized Mean Squared Error (MSE): {mse_optimized}")
print(f"Optimized R² Score: {r2_optimized}")

# Define the new input data
new_data = np.array([[25, 8.6, 3, 15, 4, 12.1, 2.5, 12]])
new_data_df = pd.DataFrame(new_data, columns=X_train.columns)
# Scale the input data using the same scaler used for training
new_data_scaled = scaler.transform(new_data_df)
# Predict the frequency
predicted_frequency = optimized_svr.predict(new_data_scaled)
print(f"Predicted Frequency (GHz): {predicted_frequency[0]}")

# Define the new input data
new_data = np.array([[26, 8.8, 5.2, 14.8, 4, 12.2, 3, 10]])
new_data_df = pd.DataFrame(new_data, columns=X_train.columns)
# Scale the input data using the same scaler used for training
new_data_scaled = scaler.transform(new_data_df)
# Predict the frequency
predicted_frequency = optimized_svr.predict(new_data_scaled)
print(f"Predicted Frequency (GHz): {predicted_frequency[0]}")

"""# **RANDOM FOREST WITHOUT GENETIC ALOGORITHM**

"""

from sklearn.ensemble import RandomForestRegressor

rf_model = RandomForestRegressor(n_estimators=100, random_state=5)
rf_model.fit(X_train_scaled, y_train)
y_pred = rf_model.predict(X_test_scaled)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"Mean Squared Error (MSE): {mse}")
print(f"R² Score: {r2}")

# Define the new input data
new_data = np.array([[25, 8.6, 3, 15, 4, 12.1, 2.5, 12]])
new_data_df = pd.DataFrame(new_data, columns=X_train.columns)
# Scale the input data using the same scaler used for training
new_data_scaled = scaler.transform(new_data_df)
# Predict the frequency
predicted_frequency = rf_model.predict(new_data_scaled)
print(f"Predicted Frequency (GHz): {predicted_frequency[0]}")

# Define the new input data
new_data = np.array([[26, 8.8, 5.2, 14.8, 4, 12.2, 3, 10]])
new_data_df = pd.DataFrame(new_data, columns=X_train.columns)
# Scale the input data using the same scaler used for training
new_data_scaled = scaler.transform(new_data_df)
# Predict the frequency
predicted_frequency = rf_model.predict(new_data_scaled)
print(f"Predicted Frequency (GHz): {predicted_frequency[0]}")

"""# **Random Forest with GA**"""

def rf_fitness(params):
  n_estimators, max_depth, min_samples_split = map(int, params)
  if n_estimators < 50 or max_depth < 5 or min_samples_split < 2:
    return float('inf'),
  rf = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, random_state=7)
  return -cross_val_score(rf, X_train_scaled, y_train, cv=3, scoring='neg_mean_squared_error').mean(),

from deap import creator

if "FitnessMin" not in creator.__dict__:
    creator.create("FitnessMin", base.Fitness, weights=(-1.0,))  # Minimize MSE

if "Individual" not in creator.__dict__:
    creator.create("Individual", list, fitness=creator.FitnessMin)

toolbox = base.Toolbox()
creator.create("FitnessMin", base.Fitness, weights=(-1.0,))
creator.create("Individual", list, fitness=creator.FitnessMin)
toolbox.register("attr_n_estimators", lambda: np.random.randint(50, 150))
toolbox.register("attr_max_depth", lambda: np.random.randint(5, 30))
toolbox.register("attr_min_samples_split", lambda: np.random.randint(2, 8))
toolbox.register("individual", tools.initIterate, creator.Individual, lambda: [toolbox.attr_n_estimators(), toolbox.attr_max_depth(), toolbox.attr_min_samples_split()])
toolbox.register("population", tools.initRepeat, list, toolbox.individual)
toolbox.register("mate", tools.cxBlend, alpha=0.5)
toolbox.register("mutate", tools.mutGaussian, mu=0, sigma=1, indpb=0.2)
toolbox.register("select", tools.selTournament, tournsize=3)
toolbox.register("evaluate", rf_fitness)

# Run GA
population = toolbox.population(n=50)
algorithms.eaSimple(population, toolbox, cxpb=0.7, mutpb=0.2, ngen=20, verbose=True)
best = tools.selBest(population, k=1)[0]
print("Best Parameters:", best)

# Train optimized model
optimized_rf = RandomForestRegressor(n_estimators=int(best[0]), max_depth=int(best[1]), min_samples_split=int(best[2]), random_state=19)
optimized_rf.fit(X_train_scaled, y_train)

# Evaluate
y_pred = optimized_rf.predict(X_test_scaled)
print(f"MSE: {mean_squared_error(y_test, y_pred)}")
print(f"R²: {r2_score(y_test, y_pred)}")

# Define the new input data
new_data = np.array([[25, 8.6, 3, 15, 4, 12.1, 2.5, 12]])
new_data_df = pd.DataFrame(new_data, columns=X_train.columns)
# Scale the input data using the same scaler used for training
new_data_scaled = scaler.transform(new_data_df)
# Predict the frequency
predicted_frequency = optimized_rf.predict(new_data_scaled)
print(f"Predicted Frequency (GHz): {predicted_frequency[0]}")

new_data = np.array([[26, 8.8, 5.2, 14.8, 4, 12.2, 3, 10]])
new_data_df = pd.DataFrame(new_data, columns=X_train.columns)
new_data_scaled = scaler.transform(new_data_df)
predicted_frequency = optimized_rf.predict(new_data_scaled)
print(f"Predicted Frequency (GHz): {predicted_frequency[0]}")

from sklearn.metrics import mean_squared_error
import numpy as np
# Actual frequency value
actual_frequency = np.array([2.0263])
# Predicted values from different models
predictions = {
    "SVR without GA": np.array([2.1199]),
    "SVR with GA": np.array([2.0547]),
    "RF without GA": np.array([2.0330]),
    "RF with GA": np.array([2.0342])
}
# Compute and display MSE for each model
for model, pred in predictions.items():
    mse = mean_squared_error(actual_frequency, pred)
    print(f"{model} - MSE: {mse:.6f}")



